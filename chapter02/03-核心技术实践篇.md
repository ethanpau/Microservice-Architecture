## 服务降级设计与实践 ##

#### 服务降级定义 ####

> 当服务整体负载超出预设的上限值或即将到来的流量预计将会超过预设阈值时，为了保证重要或基本的服务能正常运行，拒绝部分请求或将一部分不重要或不紧急的服务或任务进行服务的延迟使用或暂停使用  

#### 服务降级目的 ####
> 流量高峰期、短时请求量大（服务能力有限）—— 防止系统雪崩

#### 服务降级的目标 ####

> 保证核心服务可用；非核心服务弱可用，或甚至不可用

#### 服务降级手段 ####

- 拒绝部分请求    
	
	> - 拒绝部分老请求（降级开启条件）  
	> - 优先级请求方式（降级策略）  
	> - 随机拒绝方式  
	
- 关闭部分服务（业务相关）

#### 服务层降级架构层次 ####
- 集中式
	- 网关层
- 自治式
	- 网关层
	- 业务逻辑层
	- 数据访问层

## 服务限流/熔断设计与实践 ##

#### 熔断目的 ####

> - 微服务化之后，系统分布式部署，系统之间通过rpc框架通信，整个系统发生故障的概率随着系统规模的增长而增长，一个小的故障经过链路传导放大，有可能造成更大的故障   
> - 业务方希望在调用服务时，在一些非关键路径服务发生质量下降的情况下，尽可能选择屏蔽所造成的影响

#### 熔断需求 ####
- 大部分熔断返回默认值（null），也可定制，RPC client原生支持最好，业务方少改代码  
- 进入熔断时，打印熔断日志，同时能够返回Exception（业务方定制了熔断方法）  
- 服务治理平台可以看到服务的状态，是否限流，是否熔断，可以实时下发阈值配置 
- 可以报警，最好加上异常信息  
- 调用方粒度的确定，接口粒度

#### 服务管理平台本质 ####
- 服务可视化管理  

## 服务灰度发布设计与实践 ##

#### 灰度发布定义 ####

> 灰度发布时互联网产品常用的一种发布方式，顾名思义就是在黑和白之间平滑过渡的一种产品发布方式。产品发布者根据某种规则，让一部分用户继续使用原来的产品功能，另一部分用户开始逐渐启动新功能，在产品过渡期间可能还会对产品进一步优化完善，灰度发布完成后所有的用户都将使用新产品功能

#### 灰度发布目的 ####

- 互联网产品需要快速迭代开发上线，又要保证质量，保证刚上线的系统，一旦新上线的系统出现故障能够很快控制影响面，就需要设计一套灰度发布系统  
- 灰度发布系统的作用，可以根据配置，将用户流量导到新系统上，来快速验证新系统的功能，而一旦出现故障，也可以马上恢复，简单点说就是一套A\B Test系统

#### 服务灰度发布系统架构 ####
- 上游服务接入客户请求，根据下发的灰度配置将符合条件的请求转发到下游新旧版本服务上  
- 下游新旧版本服务是处理客户端请求的业务服务系统  
- 服务配置管理平台，此平台可以配置不同的灰度发布转发策略给上游服务  
- 注册中心，负责上下游服务的注册与发现  

## 服务全链路压测设计与实践 ##

#### 压测定义 ####
> 基于线上真是环境和实际业务场景，通过模拟海量的用户请求，来对整个系统链路进行压力测试

#### 压测目的 ####
- 验证新上线功能的稳定性
- 验证峰值流量情况下服务的稳定性和伸缩能力  
- 对线上服务进行更准确的容量评估
- 找到系统瓶颈并针对性优化

#### 压测常用工具 ####
- JMeter
	- 用于对服务器、网络或对象模拟巨大的负载，来在不同压力类别下测试它们的强度和分析整体性能
	- 支持分布式压测
- TCPCopy（流量复制工具）
	- 流量复制工具，能够把线上机器的流量导流到压测环境的机器上
	- 为营造巨大压力情况，使用Tcpdump录制请求，然后使用TCPCopy回放功能产生巨大的压力
- Apache ab
	- http

#### 压测极限标准 ####
- 机器load average 不超过CPU总核数*0.6
- 服务进程CPU占用率不超过（CPU核数\*0.6）\*100/机器部署的服务进程数
- 网卡流量不超过网卡容量的60%（超过可能延时较大）
- 请求超时不超过十万分之一
- QPS不低于预估的85%，否则需要优化，或者给出合理解释

## 互联网高可用设计手段 ##

- 系统性能  

 > 吞吐量（Throughput）  
 > 响应延迟（Response Delay） 

#### 性能优化目标 ####
- 缩短响应时间  
- 提高并发数（增加吞吐量）  
- 让系统处于合理状态  

#### 性能优化手段 ####
1. 空间换时间  

	> 系统时间是瓶颈（缓存服用计算结果，降低时间开销因为CPU时间叫内存容量更加昂贵）   
2. 时间换空间  

	> 数据大小是瓶颈  
	
	> - 网络传输是瓶颈，使用系统时间换取传输空间，使用HTTP的gzip压缩算法  
	> - App的请求分类接口，使用版本号判断哪些数据更新，指下载更新的数据
3. 找到系统瓶颈
	> 分析系统业务流程，找到关键路径并分解优化  
	
	> - 一个服务集群4w的QPS，调用量前5的接口贡献了3.5W的QPS  
	> - 对于关键路径的代码优化收益最大，当然系统剩下的部分也不能忽视，比如剩下5Kqps接口若性能有问题也可能把整体服务性能拖垮

	> ___调用了多少RPC接口，载入多少数据，使用什么算法，非核心流程能否异步化，没有数据依赖的逻辑能否并行执行___
	
#### 性能优化层次 ####
1. 架构层次  

	- 如果拆分系统，如何使个部分系统整体负载更加均衡，充分发挥硬件设施性能优势，减少系统内部开销  
	
	> - 系统微服务化  
	> - 无状态化设计，动态水平弹性扩展  
	> - 调用链路梳理，热点数据尽量靠近用户  
	> - 分布式Cache、多级多类型缓存  
	> - 提前拒绝，保障柔性可用  
	> - 容量规则  
	> - 分库分表，读写分离，数据分片  
	
2. 算法逻辑层次  

	 - 关注算法选择是否高效，算法逻辑优化，空间时间优化，任务并行处理，使用无锁数据结构等  
	 - 空间换时间  
	 - 时间换空间（采用压缩算法压缩数据更复杂的逻辑减少数据传输）  
	
	> - 用更高效算法替换现有算法，而不改变其接口  
	> - 增量式算法，复用之前的计算结果（比如一个报表服务，要从全量数据中生成表表数据量很大，但是每次增量的数据较少，则可以考虑只计算增量数据和之前计算结果合并，这样处理的数据量就小很多）  
	> - 并发和锁的优化，读多写少的业务场景下，基于CAS的LockFree比mutex性能更好  
	> - 当系统时间是瓶颈，采取空间换时间逻辑算法，分配更多空间节省系统时间  
	> - 当系统空间容量是瓶颈，采取时间换空间算法策略  
	> - 并行执行（如一段逻辑调用了多个RPC接口，而这些接口之间并没有数据依赖，则可以考虑并行调用，降低响应时间）  
	> - 异步执行，分析业务流程中的主次流程，把次要流程拆分出来异步执行，更进一步可以拆分到单独的模块去执行（比如使用消息队列，彻底和核心流程解耦，提高核心流程的稳定性以及降低响应时间）
	
3. 代码优化层次
	
	- 关注代码细节优化，代码实现是否合理，是否创建了过多的对象，循环遍历是否高效，cache使用的是否合理，是否重用计算结果等  
	 ___代码优化层次，从整体到细节，从全局角度到局部视角___

	> __代码逻辑优化__
	
	> - 循环遍历是否合理高效，不要在循环里调用RPC、查询分布式缓存、执行SQL等
	> 	- 先调用批量接口组装好数据，再循环处理
	> - 代码逻辑避免生成过多对象或无效对象
	> - ArrayList、HashMap初始化熔炼设置是否合理
	> 	- 扩容代价
	> - 对数据对象是否合理重用，比如通过RPC查到的数据能复用则必须复用  
	> - 根据数据访问特性选择合适数据结构，比如读多写少，考虑CopyOnWriteArrayList（写时Copy副本）
	> - 拼接字符串的时候使用String相加还是StringBuiler进行append（在StirngBuilder的容量预分配的情况下，StringBuilder的性能比String相加性能高15倍左右）  
	> - 是否正确初始化数据。有些全局共享数据，饿汉模式，在用户访问之前先初始化好
	
	> __数据库层次优化__  
	
	> - SQL优化（扫描数据超过30%时，并没有使用索引，合理添加检索条件使扫描数据控制在30%以内）
	> - 代码逻辑要适应数据变化的场景
	















